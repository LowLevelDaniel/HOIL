/**
 * @file lexer.h
 * @brief Lexical analyzer for HOIL language
 * 
 * This file defines the interface for the lexical analyzer (lexer)
 * that converts HOIL source code into a stream of tokens.
 *
 * @author Generated by Claude
 * @date 2025-03-13
 */

#ifndef LEXER_H
#define LEXER_H

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>

/**
 * @brief Token types for HOIL language
 */
typedef enum {
  TOKEN_EOF = 0,        /**< End of file */
  TOKEN_IDENTIFIER,     /**< Identifier */
  TOKEN_NUMBER,         /**< Numeric literal */
  TOKEN_STRING,         /**< String literal */
  TOKEN_MODULE,         /**< MODULE keyword */
  TOKEN_TYPE,           /**< TYPE keyword */
  TOKEN_CONSTANT,       /**< CONSTANT keyword */
  TOKEN_GLOBAL,         /**< GLOBAL keyword */
  TOKEN_FUNCTION,       /**< FUNCTION keyword */
  TOKEN_EXTERN,         /**< EXTERN keyword */
  TOKEN_TARGET,         /**< TARGET keyword */
  TOKEN_ENTRY,          /**< ENTRY label */
  TOKEN_RET,            /**< RET instruction */
  TOKEN_BR,             /**< BR instruction */
  TOKEN_CALL,           /**< CALL instruction */
  TOKEN_ADD,            /**< ADD instruction */
  TOKEN_SUB,            /**< SUB instruction */
  TOKEN_MUL,            /**< MUL instruction */
  TOKEN_DIV,            /**< DIV instruction */
  TOKEN_NEG,            /**< NEG instruction */
  TOKEN_REM,            /**< REM instruction */
  TOKEN_AND,            /**< AND instruction */
  TOKEN_OR,             /**< OR instruction */
  TOKEN_XOR,            /**< XOR instruction */
  TOKEN_NOT,            /**< NOT instruction */
  TOKEN_SHL,            /**< SHL instruction */
  TOKEN_SHR,            /**< SHR instruction */
  TOKEN_CMP_EQ,         /**< CMP_EQ instruction */
  TOKEN_CMP_NE,         /**< CMP_NE instruction */
  TOKEN_CMP_LT,         /**< CMP_LT instruction */
  TOKEN_CMP_LE,         /**< CMP_LE instruction */
  TOKEN_CMP_GT,         /**< CMP_GT instruction */
  TOKEN_CMP_GE,         /**< CMP_GE instruction */
  TOKEN_LOAD,           /**< LOAD instruction */
  TOKEN_STORE,          /**< STORE instruction */
  TOKEN_LEA,            /**< LEA instruction */
  TOKEN_FENCE,          /**< FENCE instruction */
  TOKEN_CONVERT,        /**< CONVERT instruction */
  TOKEN_TRUNC,          /**< TRUNC instruction */
  TOKEN_EXTEND,         /**< EXTEND instruction */
  TOKEN_VADD,           /**< VADD instruction */
  TOKEN_VDOT,           /**< VDOT instruction */
  TOKEN_VSPLAT,         /**< VSPLAT instruction */
  TOKEN_VLOAD,          /**< VLOAD instruction */
  TOKEN_ATOMIC_ADD,     /**< ATOMIC_ADD instruction */
  TOKEN_ATOMIC_CAS,     /**< ATOMIC_CAS instruction */
  TOKEN_ALWAYS,         /**< ALWAYS branch condition */
  TOKEN_LPAREN,         /**< ( */
  TOKEN_RPAREN,         /**< ) */
  TOKEN_LBRACE,         /**< { */
  TOKEN_RBRACE,         /**< } */
  TOKEN_LBRACKET,       /**< [ */
  TOKEN_RBRACKET,       /**< ] */
  TOKEN_COMMA,          /**< , */
  TOKEN_SEMICOLON,      /**< ; */
  TOKEN_COLON,          /**< : */
  TOKEN_DOT,            /**< . */
  TOKEN_ARROW,          /**< -> */
  TOKEN_EQUALS,         /**< = */
  TOKEN_ASTERISK,       /**< * */
  TOKEN_AMPERSAND,      /**< & */
  TOKEN_LESS,           /**< < */
  TOKEN_GREATER,        /**< > */
  TOKEN_ERROR           /**< Invalid token */
} token_type_t;

/**
 * @brief Token structure representing a lexical unit
 */
typedef struct {
  token_type_t type;    /**< Type of the token */
  const char* start;    /**< Pointer to start of token in source */
  size_t length;        /**< Length of token in bytes */
  size_t line;          /**< Line number in source */
  size_t column;        /**< Column number in source */
  
  union {
    double number_value;      /**< Value if token is a number */
    char* string_value;       /**< Value if token is a string (owned by token) */
    char* identifier_value;   /**< Value if token is an identifier (owned by token) */
  };
} token_t;

/**
 * @brief Lexer structure for tokenizing HOIL source
 */
typedef struct lexer_t lexer_t;

/**
 * @brief Create a new lexer instance
 * 
 * @param source Source code to tokenize
 * @param length Length of source code in bytes
 * @param filename Source filename for error reporting
 * @return Pointer to created lexer or NULL on failure
 */
lexer_t* lexer_create(const char* source, size_t length, const char* filename);

/**
 * @brief Destroy a lexer instance and free resources
 * 
 * @param lexer Lexer to destroy
 */
void lexer_destroy(lexer_t* lexer);

/**
 * @brief Get the next token from the source
 * 
 * @param lexer The lexer instance
 * @return The next token
 */
token_t lexer_next_token(lexer_t* lexer);

/**
 * @brief Peek at the next token without consuming it
 * 
 * @param lexer The lexer instance
 * @return The next token
 */
token_t lexer_peek_token(lexer_t* lexer);

/**
 * @brief Get the current line number in the source
 * 
 * @param lexer The lexer instance
 * @return Current line number
 */
size_t lexer_line(const lexer_t* lexer);

/**
 * @brief Get the current column number in the source
 * 
 * @param lexer The lexer instance
 * @return Current column number
 */
size_t lexer_column(const lexer_t* lexer);

/**
 * @brief Get the source filename
 * 
 * @param lexer The lexer instance
 * @return Source filename
 */
const char* lexer_filename(const lexer_t* lexer);

/**
 * @brief Convert token type to string for debugging
 * 
 * @param type Token type
 * @return String representation of token type
 */
const char* token_type_to_string(token_type_t type);

#endif /* LEXER_H */