/**
 * @file test_lexer.c
 * @brief Test for the HOIL lexer
 * 
 * This file contains tests for the lexical analyzer to ensure it correctly
 * tokenizes HOIL source code.
 *
 * @author Generated by Claude
 * @date 2025-03-13
 */

#include "lexer.h"
#include "error_handling.h"
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdbool.h>
#include <assert.h>

/**
 * @brief Test structure to associate input with expected token types
 */
typedef struct {
  const char* input;                /**< Input string */
  token_type_t expected_types[32];  /**< Expected token types (terminated with TOKEN_EOF) */
  const char* description;          /**< Test description */
} lexer_test_t;

/**
 * @brief Main test function
 * 
 * @return 0 on success, non-zero on failure
 */
int main() {
  // Initialize error handling
  error_init(true, true);
  
  // Define test cases
  lexer_test_t tests[] = {
    {
      "MODULE \"test\";",
      {TOKEN_MODULE, TOKEN_STRING, TOKEN_SEMICOLON, TOKEN_EOF},
      "Simple module declaration"
    },
    {
      "FUNCTION add(a: i32, b: i32) -> i32 { ENTRY: result = ADD a, b; RET result; }",
      {
        TOKEN_FUNCTION, TOKEN_IDENTIFIER, TOKEN_LPAREN, TOKEN_IDENTIFIER, TOKEN_COLON, 
        TOKEN_IDENTIFIER, TOKEN_COMMA, TOKEN_IDENTIFIER, TOKEN_COLON, TOKEN_IDENTIFIER, 
        TOKEN_RPAREN, TOKEN_ARROW, TOKEN_IDENTIFIER, TOKEN_LBRACE, TOKEN_ENTRY, 
        TOKEN_COLON, TOKEN_IDENTIFIER, TOKEN_EQUALS, TOKEN_ADD, TOKEN_IDENTIFIER, 
        TOKEN_COMMA, TOKEN_IDENTIFIER, TOKEN_SEMICOLON, TOKEN_RET, TOKEN_IDENTIFIER, 
        TOKEN_SEMICOLON, TOKEN_RBRACE, TOKEN_EOF
      },
      "Function definition"
    },
    {
      "// This is a comment\nMODULE \"test\";",
      {TOKEN_MODULE, TOKEN_STRING, TOKEN_SEMICOLON, TOKEN_EOF},
      "Line comment"
    },
    {
      "/* This is a\nmulti-line comment */\nMODULE \"test\";",
      {TOKEN_MODULE, TOKEN_STRING, TOKEN_SEMICOLON, TOKEN_EOF},
      "Multi-line comment"
    },
    {
      "CONSTANT PI: f64 = 3.14159;",
      {
        TOKEN_CONSTANT, TOKEN_IDENTIFIER, TOKEN_COLON, TOKEN_IDENTIFIER, 
        TOKEN_EQUALS, TOKEN_NUMBER, TOKEN_SEMICOLON, TOKEN_EOF
      },
      "Constant definition"
    },
    {
      "TYPE point { x: f32, y: f32 }",
      {
        TOKEN_TYPE, TOKEN_IDENTIFIER, TOKEN_LBRACE, TOKEN_IDENTIFIER, TOKEN_COLON, 
        TOKEN_IDENTIFIER, TOKEN_COMMA, TOKEN_IDENTIFIER, TOKEN_COLON, TOKEN_IDENTIFIER, 
        TOKEN_RBRACE, TOKEN_EOF
      },
      "Type definition"
    }
  };
  
  // Run tests
  int test_count = sizeof(tests) / sizeof(tests[0]);
  int passed = 0;
  int failed = 0;
  
  for (int i = 0; i < test_count; i++) {
    printf("Test %d: %s\n", i + 1, tests[i].description);
    
    // Create lexer for this test
    lexer_t* lexer = lexer_create(tests[i].input, strlen(tests[i].input), "test.hoil");
    assert(lexer != NULL);
    
    // Tokenize input and compare with expected tokens
    bool test_passed = true;
    int token_index = 0;
    
    while (true) {
      token_t token = lexer_next_token(lexer);
      
      // Check if the expected token is EOF
      if (tests[i].expected_types[token_index] == TOKEN_EOF) {
        if (token.type != TOKEN_EOF) {
          printf("  Failed: Expected EOF but got %s\n", token_type_to_string(token.type));
          test_passed = false;
        }
        break;
      }
      
      // Check if token matches expected type
      if (token.type != tests[i].expected_types[token_index]) {
        printf("  Failed: Token %d expected %s but got %s\n", 
               token_index,
               token_type_to_string(tests[i].expected_types[token_index]),
               token_type_to_string(token.type));
        test_passed = false;
      }
      
      token_index++;
      
      // Check for array overflow
      if (token_index >= 16) {
        printf("  Failed: Too many tokens\n");
        test_passed = false;
        break;
      }
      
      // Break on EOF
      if (token.type == TOKEN_EOF) {
        break;
      }
    }
    
    // Check if we have more expected tokens
    if (test_passed && tests[i].expected_types[token_index] != TOKEN_EOF) {
      printf("  Failed: Not enough tokens\n");
      test_passed = false;
    }
    
    // Clean up
    lexer_destroy(lexer);
    
    // Update counters
    if (test_passed) {
      printf("  Passed\n");
      passed++;
    } else {
      failed++;
    }
    
    printf("\n");
  }
  
  // Print summary
  printf("Tests completed: %d passed, %d failed\n", passed, failed);
  
  return failed > 0 ? 1 : 0;
}